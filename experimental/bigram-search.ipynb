{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Efficient bigram search\n",
    "\n",
    "Creates a table containing only bigrams, then demonstrates a search query on this table. Searching a single word on this table can be useful for a quick text check when building classifiers.\n",
    "\n",
    "The table can be saved to a parquet file for easy loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kalyan/Library/Caches/pypoetry/virtualenvs/open-data-cnKQNmjn-py3.12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import duckdb\n",
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 15 files: 100%|██████████| 15/15 [00:00<00:00, 2485.86it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/Users/kalyan/Documents/CPR/open-data/cache'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "REPO_NAME = \"ClimatePolicyRadar/all-document-text-data\"\n",
    "REPO_URL = f\"https://huggingface.co/datasets/{REPO_NAME}\"\n",
    "CACHE_DIR = \"../cache\"\n",
    "\n",
    "REVISION = \"main\"  # Use this to set a commit hash. Recommended!\n",
    "\n",
    "snapshot_download(\n",
    "    repo_id=REPO_NAME,\n",
    "    repo_type=\"dataset\",\n",
    "    local_dir=CACHE_DIR,\n",
    "    revision=REVISION,\n",
    "    allow_patterns=[\"*.parquet\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "┌──────────────┬─────────────────────────────┐\n",
       "│ count_star() │ count(DISTINCT document_id) │\n",
       "│    int64     │            int64            │\n",
       "├──────────────┼─────────────────────────────┤\n",
       "│     21037269 │                        7795 │\n",
       "└──────────────┴─────────────────────────────┘"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = duckdb.connect()\n",
    "\n",
    "# Authenticate (needed if loading a private dataset)\n",
    "# You'll need to log in using `huggingface-cli login` in your terminal first\n",
    "db.execute(\"CREATE SECRET hf_token (TYPE HUGGINGFACE, PROVIDER credential_chain);\")\n",
    "\n",
    "# Create a view called 'open_data', and count the number of rows and distinct documents\n",
    "# in the view\n",
    "db.execute(\n",
    "    f\"CREATE VIEW open_data AS SELECT * FROM read_parquet('{CACHE_DIR}/*.parquet')\"\n",
    ")\n",
    "db.sql(\"SELECT COUNT(*), COUNT(DISTINCT document_id) FROM open_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   0%|          | 0/211 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 211/211 [04:06<00:00,  1.17s/it]\n"
     ]
    }
   ],
   "source": [
    "def create_bigram_table(conn, source_table: str, batch_size: int = 100000) -> None:\n",
    "    # Get the total count of rows in the source table\n",
    "    total_rows = conn.execute(f\"SELECT COUNT(*) FROM {source_table}\").fetchone()[0]\n",
    "\n",
    "    conn.execute(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS bigrams (\n",
    "            bigram VARCHAR PRIMARY KEY,\n",
    "            frequency INTEGER\n",
    "        )\n",
    "    \"\"\")\n",
    "\n",
    "    # Process the data in batches\n",
    "    for offset in tqdm(range(0, total_rows, batch_size), desc=\"Processing batches\"):\n",
    "        conn.execute(f\"\"\"\n",
    "            INSERT INTO bigrams\n",
    "            WITH words AS (\n",
    "                SELECT unnest(string_split(lower(\"text_block.text\"), ' ')) AS word\n",
    "                FROM {source_table}\n",
    "                LIMIT {batch_size} OFFSET {offset}\n",
    "            ),\n",
    "            bigram_pairs AS (\n",
    "                SELECT \n",
    "                    word || ' ' || lead(word, 1) OVER (ORDER BY (SELECT NULL)) AS bigram\n",
    "                FROM words\n",
    "            ),\n",
    "            batch_bigrams AS (\n",
    "                SELECT bigram, COUNT(*) AS frequency\n",
    "                FROM bigram_pairs\n",
    "                WHERE bigram IS NOT NULL\n",
    "                GROUP BY bigram\n",
    "            )\n",
    "            SELECT bigram, frequency FROM batch_bigrams\n",
    "            ON CONFLICT (bigram) DO UPDATE SET\n",
    "            frequency = bigrams.frequency + EXCLUDED.frequency\n",
    "        \"\"\")\n",
    "\n",
    "    # Create an index on the bigram column for faster searching (if not already created by PRIMARY KEY)\n",
    "    conn.execute(\"CREATE INDEX IF NOT EXISTS bigram_idx ON bigrams(bigram)\")\n",
    "\n",
    "\n",
    "create_bigram_table(db, \"open_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('climate change', 16323),\n",
       " ('climate change.', 2365),\n",
       " ('climate change,', 2146),\n",
       " ('national climate', 1595),\n",
       " ('climate policy', 932),\n",
       " ('climate risks', 734),\n",
       " ('climate finance', 662),\n",
       " ('climate adaptation', 659),\n",
       " ('climate action', 647),\n",
       " ('climate financing', 528)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords = [\n",
    "    \"i\",\n",
    "    \"me\",\n",
    "    \"my\",\n",
    "    \"myself\",\n",
    "    \"we\",\n",
    "    \"our\",\n",
    "    \"ours\",\n",
    "    \"ourselves\",\n",
    "    \"you\",\n",
    "    \"your\",\n",
    "    \"yours\",\n",
    "    \"yourself\",\n",
    "    \"yourselves\",\n",
    "    \"he\",\n",
    "    \"him\",\n",
    "    \"his\",\n",
    "    \"himself\",\n",
    "    \"she\",\n",
    "    \"her\",\n",
    "    \"hers\",\n",
    "    \"herself\",\n",
    "    \"it\",\n",
    "    \"its\",\n",
    "    \"itself\",\n",
    "    \"they\",\n",
    "    \"them\",\n",
    "    \"their\",\n",
    "    \"theirs\",\n",
    "    \"themselves\",\n",
    "    \"what\",\n",
    "    \"which\",\n",
    "    \"who\",\n",
    "    \"whom\",\n",
    "    \"this\",\n",
    "    \"that\",\n",
    "    \"these\",\n",
    "    \"those\",\n",
    "    \"am\",\n",
    "    \"is\",\n",
    "    \"are\",\n",
    "    \"was\",\n",
    "    \"were\",\n",
    "    \"be\",\n",
    "    \"been\",\n",
    "    \"being\",\n",
    "    \"have\",\n",
    "    \"has\",\n",
    "    \"had\",\n",
    "    \"having\",\n",
    "    \"do\",\n",
    "    \"does\",\n",
    "    \"did\",\n",
    "    \"doing\",\n",
    "    \"a\",\n",
    "    \"an\",\n",
    "    \"the\",\n",
    "    \"and\",\n",
    "    \"but\",\n",
    "    \"if\",\n",
    "    \"or\",\n",
    "    \"because\",\n",
    "    \"as\",\n",
    "    \"until\",\n",
    "    \"while\",\n",
    "    \"of\",\n",
    "    \"at\",\n",
    "    \"by\",\n",
    "    \"for\",\n",
    "    \"with\",\n",
    "    \"about\",\n",
    "    \"against\",\n",
    "    \"between\",\n",
    "    \"into\",\n",
    "    \"through\",\n",
    "    \"during\",\n",
    "    \"before\",\n",
    "    \"after\",\n",
    "    \"above\",\n",
    "    \"below\",\n",
    "    \"to\",\n",
    "    \"from\",\n",
    "    \"up\",\n",
    "    \"down\",\n",
    "    \"in\",\n",
    "    \"out\",\n",
    "    \"on\",\n",
    "    \"off\",\n",
    "    \"over\",\n",
    "    \"under\",\n",
    "    \"again\",\n",
    "    \"further\",\n",
    "    \"then\",\n",
    "    \"once\",\n",
    "    \"here\",\n",
    "    \"there\",\n",
    "    \"when\",\n",
    "    \"where\",\n",
    "    \"why\",\n",
    "    \"how\",\n",
    "    \"all\",\n",
    "    \"any\",\n",
    "    \"both\",\n",
    "    \"each\",\n",
    "    \"few\",\n",
    "    \"more\",\n",
    "    \"most\",\n",
    "    \"other\",\n",
    "    \"some\",\n",
    "    \"such\",\n",
    "    \"no\",\n",
    "    \"nor\",\n",
    "    \"not\",\n",
    "    \"only\",\n",
    "    \"own\",\n",
    "    \"same\",\n",
    "    \"so\",\n",
    "    \"than\",\n",
    "    \"too\",\n",
    "    \"very\",\n",
    "    \"s\",\n",
    "    \"t\",\n",
    "    \"can\",\n",
    "    \"will\",\n",
    "    \"just\",\n",
    "    \"don\",\n",
    "    \"should\",\n",
    "    \"now\",\n",
    "]\n",
    "\n",
    "stopwords_condition = \" AND \".join(\n",
    "    [f\"bigram NOT SIMILAR TO '.*\\\\b{word}\\\\b.*'\" for word in stopwords]\n",
    ")\n",
    "\n",
    "\n",
    "def search_bigrams(db, search_term: str, limit: int = 100) -> list[tuple[str, int]]:\n",
    "    result = db.execute(f\"\"\"\n",
    "        SELECT DISTINCT bigram, frequency\n",
    "        FROM bigrams\n",
    "        WHERE bigram LIKE '%{search_term.lower()}%'\n",
    "        AND {stopwords_condition}\n",
    "        ORDER BY frequency DESC, bigram\n",
    "        LIMIT {limit} \n",
    "    \"\"\")\n",
    "\n",
    "    return result.fetchall()\n",
    "\n",
    "\n",
    "search_bigrams(db, \"climate\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.sql(\"COPY bigrams TO 'bigrams.parquet' (FORMAT PARQUET);\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "open-data-cnKQNmjn-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
